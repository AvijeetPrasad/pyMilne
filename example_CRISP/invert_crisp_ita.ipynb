{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import inv_utils as iu\n",
    "import me_utils as meu\n",
    "from helita.io import lp\n",
    "from einops import rearrange\n",
    "import hmi_plot as hp\n",
    "from uncertainties import  unumpy\n",
    "import importlib\n",
    "import warnings\n",
    "# Suppress the specific warning\n",
    "warnings.filterwarnings(\"ignore\", message=\"The value of the smallest subnormal for <class 'numpy.float32'> type is zero\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"The value of the smallest subnormal for <class 'numpy.float64'> type is zero\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "importlib.reload(iu)\n",
    "importlib.reload(meu)\n",
    "print('reloaded') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the configuration from the JSON file\n",
    "input_config = iu.load_yaml_config('input_config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the input configuration\n",
    "config = iu.check_input_config(input_config, pprint=True, confirm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract the input parameters\n",
    "data_dir = config['data_dir']\n",
    "save_dir = config['save_dir']\n",
    "crisp_im = config['crisp_im']\n",
    "xorg = config['xorg']\n",
    "xsize = config['xsize']\n",
    "yorg = config['yorg']\n",
    "ysize = config['ysize']\n",
    "xrange = config['xrange']\n",
    "yrange = config['yrange']\n",
    "tt = config['time_index']\n",
    "scale = config['scale']\n",
    "is_north_up = config['is_north_up']\n",
    "crop = config['crop']\n",
    "shape = config['shape']\n",
    "best_frame = config['best_frame']\n",
    "contrasts = config['contrasts']\n",
    "hmi_con_series = config['hmi_con_series']\n",
    "hmi_mag_series = config['hmi_mag_series']\n",
    "email = config['email']\n",
    "fov_angle = config['fov_angle']\n",
    "plot_sst_pointings_flag = config['plot_sst_pointings_flag']\n",
    "plot_hmi_ic_mag_flag = config['plot_hmi_ic_mag_flag']\n",
    "plot_crisp_image_flag = config['plot_crisp_image_flag']\n",
    "verbose = config['verbose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the fits information from the header\n",
    "fits_info = config['fits_info']\n",
    "nx = fits_info['nx']\n",
    "ny = fits_info['ny']\n",
    "mu = fits_info['mu']\n",
    "x1 = fits_info['hplnt'][tt][0]\n",
    "x2 = fits_info['hplnt'][tt][1]\n",
    "y1 = fits_info['hpltt'][tt][0]\n",
    "y2 = fits_info['hpltt'][tt][1]\n",
    "tobs = fits_info['all_start_times'][tt]\n",
    "tstart = fits_info['start_time_obs']\n",
    "tend = fits_info['end_time_obs']\n",
    "hplnt = fits_info['hplnt']\n",
    "hpltt = fits_info['hpltt']\n",
    "all_start_times = fits_info['all_start_times']\n",
    "central_wavelength = fits_info['central_wavelength']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the x and y ranges if cropping is enabled\n",
    "if crop:\n",
    "    x_list = np.linspace(x1, x2, num=nx)\n",
    "    y_list = np.linspace(y1, y2, num=ny)\n",
    "    x_list = x_list[xrange[0]:xrange[1]]\n",
    "    y_list = y_list[yrange[0]:yrange[1]]\n",
    "    x1 = x_list[0]\n",
    "    x2 = x_list[-1]\n",
    "    y1 = y_list[0]\n",
    "    y2 = y_list[-1]\n",
    "    nx = xsize\n",
    "    ny = ysize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_sst_pointings_flag:\n",
    "    hp.plot_sst_pointings(tstart, hmi_con_series, hplnt, hpltt,figsize=(6, 6), email=email, save_dir=save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_hmi_ic_mag_flag:\n",
    "    hp.plot_hmi_ic_mag(tobs, hmi_con_series, hmi_mag_series, email, x1, x2, y1, y2, save_dir=save_dir, figsize=(10, 5),  is_north_up=is_north_up, fov_angle=fov_angle, shape=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_crisp_image_flag:\n",
    "    print('SST CRISP image with North up:', not(is_north_up))\n",
    "    iu.plot_crisp_image(crisp_im, tt=tt, ss=0, ww=0, figsize=(6,6), fontsize=10, rot_fov=fov_angle, north_up=not(is_north_up), crop=crop, xrange=xrange, yrange=yrange, xtick_range=[x1,x2], ytick_range=[y1,y2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inversion_config = iu.load_yaml_config('inversion_config.yaml')\n",
    "# Load the variables from the inversion configuration\n",
    "dtype = inversion_config['dtype']\n",
    "nthreads = inversion_config['nthreads']\n",
    "sigma_strength= inversion_config['sigma_strength']\n",
    "sigma_list = inversion_config['sigma_list']\n",
    "erh = inversion_config['erh']\n",
    "init_model_params = inversion_config['init_model_params']\n",
    "nRandom1 = inversion_config['nRandom1']\n",
    "nIter1 = inversion_config['nIter1']\n",
    "chi2_thres1 = inversion_config['chi2_thres1']\n",
    "median_filter_chi2_mean_thres = inversion_config['median_filter_chi2_mean_thres']\n",
    "median_filter_size = inversion_config['median_filter_size']\n",
    "nRandom2 = inversion_config['nRandom2']\n",
    "nIter2 = inversion_config['nIter2']\n",
    "chi2_thres2 = inversion_config['chi2_thres2']\n",
    "nIter3 = inversion_config['nIter3']\n",
    "chi2_thres3 = inversion_config['chi2_thres3']\n",
    "alpha_strength = inversion_config['alpha_strength']\n",
    "alpha_list = inversion_config['alpha_list']\n",
    "nan_mask_replacements = inversion_config['nan_mask_replacements']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = meu.load_crisp_frame(crisp_im, tt, crop=crop, xrange=xrange, yrange=yrange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, sig, l0, me = meu.init_me_model(ll, sigma_strength, sigma_list, erh=erh, dtype=dtype, nthreads=nthreads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Imodel = meu.init_model(me, ny, nx, init_model_params=init_model_params, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Imodel, syn, chi2 = meu.run_randomised_me_inversion(Imodel, me, obs, sig, nRandom=nRandom1, nIter=nIter1, chi2_thres=chi2_thres1, mu=mu, verbose=verbose)\n",
    "masked_chi2_mean = iu.masked_mean(chi2, ll.mask)\n",
    "if verbose:\n",
    "    print(f'Masked chi2 mean: {masked_chi2_mean:.2f}')\n",
    "    iu.plot_inversion_output(Imodel, ll.mask, scale=scale, save_fig=False)\n",
    "    iu.plot_mag(Imodel, ll.mask, scale=scale, save_fig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Imodel = meu.apply_median_filter_based_on_chi2(Imodel, masked_chi2_mean, median_filter_chi2_mean_thres, median_filter_size)\n",
    "if verbose:    \n",
    "    iu.plot_inversion_output(Imodel,ll.mask,scale=scale, save_fig=False)\n",
    "    iu.plot_mag(Imodel,ll.mask,scale=scale, save_fig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Imodel, syn, chi2 = meu.run_randomised_me_inversion(Imodel, me, obs, sig, nRandom=nRandom2, nIter=nIter2, chi2_thres=chi2_thres2, mu=mu, verbose=verbose)\n",
    "masked_chi2_mean = iu.masked_mean(chi2, ll.mask)\n",
    "if verbose:\n",
    "    print(f'Masked chi2 mean: {masked_chi2_mean:.2f}')\n",
    "    iu.plot_inversion_output(Imodel, ll.mask, scale=scale, save_fig=False)\n",
    "    iu.plot_mag(Imodel, ll.mask, scale=scale, save_fig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo, syn, chi2 = meu.run_spatially_regularized_inversion(me, Imodel, obs, sig, nIter3, chi2_thres3, mu, alpha_strength, alpha_list, method=1, delay_bracket=3, dtype=dtype,verbose=True)\n",
    "errors = me.estimate_uncertainties(np.squeeze(mo), obs, sig, mu=mu)\n",
    "corrected_mo = meu.correct_velocities_for_cavity_error(mo, ll.cmap, l0, global_offset=0.0)\n",
    "if verbose:\n",
    "    print(f'Masked chi2 mean: {masked_chi2_mean:.2f}')\n",
    "    iu.plot_inversion_output(corrected_mo,ll.mask,scale=scale, save_fig=False)\n",
    "    iu.plot_mag(corrected_mo,ll.mask,scale=scale, save_fig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_model= meu.apply_mask_to_model(corrected_mo, ll.mask, nan_mask_replacements)\n",
    "masked_errors = meu.apply_mask_to_model(errors, ll.mask, nan_mask_replacements)\n",
    "if verbose:\n",
    "    print(f'Masked chi2 mean: {masked_chi2_mean:.2f}')\n",
    "    iu.plot_inversion_output(masked_model,mask=None,scale=scale, save_fig=False)\n",
    "    iu.plot_inversion_output(masked_errors,mask=None,scale=scale, save_fig=False, apply_median_filter=True, filter_index=[1,2], filter_size=3)\n",
    "    iu.plot_mag(masked_model,mask=None,scale=scale, save_fig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iu.plot_sst_blos_bhor(blos_cube, bhor_cube, tt=tt,xrange=xrange, yrange=yrange, figsize=(20,10), fontsize=12, crop=crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(iu)\n",
    "importlib.reload(meu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_im = rearrange(masked_model, 'ny nx nparams -> nparams ny nx')\n",
    "errors_im = rearrange(masked_errors, 'ny nx nparams -> nparams ny nx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create arrays with uncertainties\n",
    "B_with_errors = unumpy.uarray(model_im[0], errors_im[0])\n",
    "inc_with_errors = unumpy.uarray(model_im[1], errors_im[1])\n",
    "\n",
    "# Calculate Blos and Bhor with propagated errors\n",
    "Blos_with_errors = B_with_errors * unumpy.cos(inc_with_errors)\n",
    "Bhor_with_errors = B_with_errors * unumpy.sin(inc_with_errors)\n",
    "\n",
    "# Extract nominal values and standard deviations\n",
    "Blos = unumpy.nominal_values(Blos_with_errors)\n",
    "Blos_err = unumpy.std_devs(Blos_with_errors)\n",
    "\n",
    "Bhor = unumpy.nominal_values(Bhor_with_errors)\n",
    "Bhor_err = unumpy.std_devs(Bhor_with_errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bhor_err_clipped = np.clip(Bhor_err, a_min=0, a_max=np.max(Bhor))\n",
    "Blos_err_clipped = np.clip(Blos_err, a_min=0, a_max=np.max(np.abs(Blos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extend model_im by adding Blos and Bhor and 10 and 11 indices\n",
    "model_im = np.concatenate((model_im, Blos[np.newaxis], Bhor[np.newaxis]), axis=0)\n",
    "errors_im = np.concatenate((errors_im, Blos_err_clipped[np.newaxis], Bhor_err_clipped[np.newaxis]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idl_model_im = rearrange(model_im, 'nparams ny nx -> nparams nx ny')\n",
    "idl_errors_im = rearrange(errors_im, 'nparams ny nx -> nparams nx ny')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idl_model_im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine input_config and inversion_config dictionaries\n",
    "full_config = {**input_config, **inversion_config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits_header = iu.load_fits_header(crisp_im, out_dict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inversion_out_list = [\"Bstr\", \"Binc\", \"Bazi\", \"Vlos\", \"Vdop\", \"etal\", \"damp\", \"S0\", \"S1\", \"Blos\", \"Bhor\"]\n",
    "inverstion_error_out_list = [\"Bstr_err\", \"Binc_err\", \"Bazi_err\", \"Vlos_err\", \"Vdop_err\", \"etal_err\", \"damp_err\", \"S0_err\", \"S1_err\", \"Blos_err\", \"Bhor_err\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inversion_save_fits_list = [\"Bstr\", \"Binc\", \"Bazi\", \"Vlos\", \"Blos\", \"Bhor\"]\n",
    "inversion_save_errors = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_string = all_start_times[tt].replace(':', '').replace(' ', '_T')\n",
    "for var in inversion_save_fits_list:\n",
    "    var_index = inversion_out_list.index(var)\n",
    "    out_file_name = save_dir + f'{inversion_out_list[var_index]}_{str(int(central_wavelength))}_{time_string}.fits'\n",
    "    iu.save_fits(idl_model_im[var_index], fits_header, out_file_name, overwrite=True)\n",
    "    if inversion_save_errors:\n",
    "        out_file_name = save_dir + f'{inversion_out_list[var_index]}_err_{str(int(central_wavelength))}_{time_string}.fits'\n",
    "        iu.save_fits(idl_errors_im[var_index], fits_header, out_file_name, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "\n",
    "def make_lp_header(array, nt=None, t_start=None, delta_t=None):\n",
    "    \"\"\"\n",
    "    Create a standard header for saving La Palma data.\n",
    "    \n",
    "    Parameters:\n",
    "        array (numpy.ndarray): The data array.\n",
    "        nt (int, optional): Number of time steps.\n",
    "        t_start (str, optional): Start time.\n",
    "        delta_t (str, optional): Time interval.\n",
    "    \n",
    "    Returns:\n",
    "        str: The header string.\n",
    "    \"\"\"\n",
    "    # Check image dimensions\n",
    "    sZ = array.shape\n",
    "    dims = len(sZ)\n",
    "    \n",
    "    if dims < 2:\n",
    "        raise ValueError(\"Only 2D or 3D files are supported\")\n",
    "    \n",
    "    datatype_map = {\n",
    "        np.uint8: 1,\n",
    "        np.int16: 2,\n",
    "        np.int32: 3,\n",
    "        np.float32: 4\n",
    "    }\n",
    "    \n",
    "    datatype = datatype_map.get(array.dtype.type, 4)\n",
    "    if nt is not None:\n",
    "        dims = 3\n",
    "    if dims == 2:\n",
    "        ny, nx = sZ\n",
    "        nt = 1\n",
    "    else:\n",
    "        nt, ny, nx = sZ\n",
    "    \n",
    "    header = f\"datatype={datatype}, dims={dims}, nx={nx}, ny={ny}, nt={nt}\"\n",
    "    \n",
    "    endianstr = 'l' if struct.unpack('<I', struct.pack('=I', 1))[0] == 1 else 'b'\n",
    "    header += f\", endian={endianstr}\"\n",
    "    \n",
    "    if t_start is not None:\n",
    "        header += f\", t_start={t_start}\"\n",
    "    if delta_t is not None:\n",
    "        header += f\", delta_t={delta_t}\" if isinstance(delta_t, str) else f\", delta_t={str(delta_t)}\"\n",
    "    \n",
    "    return header\n",
    "\n",
    "def lp_write(image, filename, extraheader=''):\n",
    "    \"\"\"\n",
    "    Writes La Palma data to a file with a specified header.\n",
    "    \n",
    "    Parameters:\n",
    "        image (numpy.ndarray): The image data to write.\n",
    "        filename (str): The file to write the data to.\n",
    "        extraheader (str, optional): Additional header information.\n",
    "    \"\"\"\n",
    "    # Check image dimensions\n",
    "    sZ = image.shape\n",
    "    dims = len(sZ)\n",
    "    \n",
    "    if dims < 2:\n",
    "        raise ValueError(\"Only 2D or 3D files are supported\")\n",
    "    \n",
    "    if dims == 2:\n",
    "        # Convert 2D array to 3D array with 1 timestep\n",
    "        image = image[np.newaxis, :, :]\n",
    "        sZ = image.shape\n",
    "        dims = len(sZ)\n",
    "    \n",
    "    if dims == 3:\n",
    "        # Reorder dimensions to (nt, nx, ny)\n",
    "        image = image.transpose((0, 2, 1))\n",
    "        sZ = image.shape\n",
    "    \n",
    "    nt, nx, ny = sZ\n",
    "    datatype = image.dtype\n",
    "    \n",
    "    # Create the header\n",
    "    bheader = make_lp_header(image, nt)\n",
    "    header = extraheader + ' : ' + bheader\n",
    "    \n",
    "    with open(filename, 'wb') as f:\n",
    "        # Write the header (first 512 bytes)\n",
    "        header_bytes = header.encode('ascii')\n",
    "        header_bytes_padded = header_bytes.ljust(512, b'\\x00')\n",
    "        f.write(header_bytes_padded)\n",
    "        \n",
    "        # Convert image to float32 if the datatype is not supported\n",
    "        if datatype not in [np.uint8, np.int16, np.int32, np.float32]:\n",
    "            image = image.astype(np.float32)\n",
    "            datatype = image.dtype\n",
    "\n",
    "        # Write the image data\n",
    "        f.write(image.tobytes())\n",
    "\n",
    "# # Example usage\n",
    "# image = np.random.rand(10, 100, 100).astype(np.float32)  # Example 3D image (nt, ny, nx)\n",
    "# filename = 'example.lp'\n",
    "# extraheader = 'Additional Header Information'\n",
    "# lp_write(image, filename, extraheader)\n",
    "\n",
    "\n",
    "### This version of lp_write works, but need to check whether to transpose the data or not. Currently it thinks that it is doing a ny, nx flip to nx, ny, but it is not!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "\n",
    "def make_lp_header(array, nt=None, t_start=None, delta_t=None):\n",
    "    \"\"\"\n",
    "    Create a standard header for saving La Palma data.\n",
    "    \n",
    "    Parameters:\n",
    "        array (numpy.ndarray): The data array.\n",
    "        nt (int, optional): Number of time steps.\n",
    "        t_start (str, optional): Start time.\n",
    "        delta_t (str, optional): Time interval.\n",
    "    \n",
    "    Returns:\n",
    "        str: The header string.\n",
    "    \"\"\"\n",
    "    # Check image dimensions\n",
    "    sZ = array.shape\n",
    "    dims = len(sZ)\n",
    "    \n",
    "    if dims < 2:\n",
    "        raise ValueError(\"Only 2D or 3D files are supported\")\n",
    "    \n",
    "    datatype_map = {\n",
    "        np.uint8: 1,\n",
    "        np.int16: 2,\n",
    "        np.int32: 3,\n",
    "        np.float32: 4\n",
    "    }\n",
    "    \n",
    "    datatype = datatype_map.get(array.dtype.type, 4)\n",
    "    if nt is not None:\n",
    "        dims = 3\n",
    "    if dims == 2:\n",
    "        ny, nx = sZ\n",
    "        nt = 1\n",
    "    else:\n",
    "        nt, ny, nx = sZ\n",
    "    \n",
    "    header = f\"datatype={datatype}, dims={dims}, nx={nx}, ny={ny}, nt={nt}\"\n",
    "    \n",
    "    endianstr = 'l' if struct.unpack('<I', struct.pack('=I', 1))[0] == 1 else 'b'\n",
    "    header += f\", endian={endianstr}\"\n",
    "    \n",
    "    if t_start is not None:\n",
    "        header += f\", t_start={t_start}\"\n",
    "    if delta_t is not None:\n",
    "        header += f\", delta_t={delta_t}\" if isinstance(delta_t, str) else f\", delta_t={str(delta_t)}\"\n",
    "    \n",
    "    return header\n",
    "\n",
    "def lp_write(image, filename, extraheader='', order='nt nx ny'):\n",
    "    \"\"\"\n",
    "    Writes La Palma data to a file with a specified header.\n",
    "    \n",
    "    Parameters:\n",
    "        image (numpy.ndarray): The image data to write.\n",
    "        filename (str): The file to write the data to.\n",
    "        extraheader (str, optional): Additional header information.\n",
    "        order (str, optional): Order of the input data dimensions.\n",
    "                               Default is 'nt nx ny'. Other option is 'nt ny nx'.\n",
    "    \"\"\"\n",
    "    # Check image dimensions\n",
    "    sZ = image.shape\n",
    "    dims = len(sZ)\n",
    "    \n",
    "    if dims < 2:\n",
    "        raise ValueError(\"Only 2D or 3D files are supported\")\n",
    "    \n",
    "    if dims == 2:\n",
    "        # Convert 2D array to 3D array with 1 timestep\n",
    "        image = image[np.newaxis, :, :]\n",
    "        sZ = image.shape\n",
    "        dims = len(sZ)\n",
    "    \n",
    "    if order == 'nt ny nx':\n",
    "        # Reorder dimensions to (nt, nx, ny)\n",
    "        image = image.transpose((0, 2, 1))\n",
    "    elif order != 'nt nx ny':\n",
    "        raise ValueError(\"Invalid order specified. Use 'nt nx ny' or 'nt ny nx'.\")\n",
    "    \n",
    "    sZ = image.shape\n",
    "    nt, nx, ny = sZ\n",
    "    datatype = image.dtype\n",
    "    \n",
    "    # Create the header\n",
    "    bheader = make_lp_header(image, nt)\n",
    "    header = extraheader + ' : ' + bheader\n",
    "    \n",
    "    with open(filename, 'wb') as f:\n",
    "        # Write the header (first 512 bytes)\n",
    "        header_bytes = header.encode('ascii')\n",
    "        header_bytes_padded = header_bytes.ljust(512, b'\\x00')\n",
    "        f.write(header_bytes_padded)\n",
    "        \n",
    "        # Convert image to float32 if the datatype is not supported\n",
    "        if datatype not in [np.uint8, np.int16, np.int32, np.float32]:\n",
    "            image = image.astype(np.float32)\n",
    "            datatype = image.dtype\n",
    "\n",
    "        # Write the image data\n",
    "        f.write(image.tobytes())\n",
    "\n",
    "# Example usage\n",
    "# image = np.random.rand(10, 100, 100).astype(np.float32)  # Example 3D image (nt, ny, nx)\n",
    "# filename = 'example.lp'\n",
    "# extraheader = 'Additional Header Information'\n",
    "# lp_write(image, filename, extraheader, order='nt ny nx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bazi_im = idl_model_im[2]\n",
    "blos_im = idl_model_im[-2]\n",
    "bhor_im = idl_model_im[-1]\n",
    "blos_im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'temp/test_blos.fcube'\n",
    "extraheader = 'Additional Header Information'\n",
    "lp_write(blos_im, filename, extraheader, order='nt nx ny') # it is still confusing between nx, ny order. need to think on this and fix it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape model_im[0] to (1, nx, ny) \n",
    "bazi_im = model_im[2].reshape(ny,1, 1, nx)\n",
    "blos_im = model_im[-2].reshape(ny,1, 1, nx)\n",
    "bhor_im = model_im[-1].reshape(ny,1, 1, nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(blos_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blos_im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lp.writeto('Bazi_6173_2020-08-07_T083019.fcube', bazi_im, dtype='float32')\n",
    "# lp.writeto('Blos_6173_2020-08-07_T083019.fcube', blos_im, dtype='float32')\n",
    "# lp.writeto('Bhor_6173_2020-08-07_T083019.fcube', bhor_im, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write(blos_im, 'New_Blos_6173_2020-08-07_T083019', stokes=False, sp=False, path='temp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeto('temp/Bazi_6173_2020-08-07_T083019.fcube', model_im[2], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeto(filename, image, extraheader='', dtype=None, verbose=False,\n",
    "            append=False):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_im[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = iu.load_fits_data(out_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iu.plot_image(ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh = iu.load_fits_header('temp/inv_mos.fits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Things to complete\n",
    "- [x] Move all the inputs to a dictionary and later save them in the header of the output file. Also add the best seeing frame number.\n",
    "- [x] Move the preprocessing steps like plotting and FOV details as an optional but default true step\n",
    "- [x] Plot a rectangle to show cropping region is true\n",
    "- [ ] Save fits with [blos, theta, phi, vlos + errors + mask] for each frame (temporarily) and later combine for final fits\n",
    "- [ ] Check for option to convert to fcube and icube formats using ispy or helita tools\n",
    "- [ ] Add option to do only one frame separately if user wants.\n",
    "- [ ] Add fov angle and other inputs needed for ambiguity resolution and remap in header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To do for final cube\n",
    "- [x] Pick the best seeing frame from the dataset\n",
    "- [x] Run the full inversion for the best seeing frame\n",
    "- [ ] Use this output as an initial guess for the other frames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymilne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
