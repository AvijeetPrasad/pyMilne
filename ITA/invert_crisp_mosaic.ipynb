{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Milne Eddington Inversion of SST/CRISP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries, custom libraries and setting the python path\n",
    "from load_env_and_set_pythonpath import print_pythonpath\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "from uncertainties import  unumpy\n",
    "import os\n",
    "import inversion_utils as iu\n",
    "import me_utils as meu\n",
    "import helita_io_lp as lp\n",
    "import hmi_plot as hp\n",
    "print_pythonpath()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the libraries to get the changes\n",
    "import importlib\n",
    "importlib.reload(iu)\n",
    "importlib.reload(meu)\n",
    "print(\"All libraries reloaded successfully\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the configuration from the JSON file\n",
    "input_config = iu.load_yaml_config('input_config.yaml')\n",
    "# Check the input configuration\n",
    "config = iu.check_input_config(input_config, pprint=True, confirm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract the input parameters\n",
    "data_dir = config['data_dir']\n",
    "save_dir = config['save_dir']\n",
    "crisp_im = config['crisp_im']\n",
    "xorg = config['xorg']\n",
    "xsize = config['xsize']\n",
    "yorg = config['yorg']\n",
    "rescale = config['rescale']\n",
    "ysize = config['ysize']\n",
    "xrange = config['xrange']\n",
    "yrange = config['yrange']\n",
    "time_range = config['time_range']\n",
    "best_frame_index = config['best_frame_index']\n",
    "scale = config['scale']\n",
    "is_north_up = config['is_north_up']\n",
    "flip_lr = config['flip_lr']\n",
    "crop = config['crop']\n",
    "shape = config['shape']\n",
    "best_frame = config['best_frame']\n",
    "contrasts = config['contrasts']\n",
    "hmi_con_series = config['hmi_con_series']\n",
    "hmi_mag_series = config['hmi_mag_series']\n",
    "email = config['email']\n",
    "fov_angle = config['fov_angle']\n",
    "plot_sst_pointings_flag = config['plot_sst_pointings_flag']\n",
    "plot_hmi_ic_mag_flag = config['plot_hmi_ic_mag_flag']\n",
    "plot_crisp_image_flag = config['plot_crisp_image_flag']\n",
    "blos_min = config['blos_min']\n",
    "blos_max = config['blos_max']\n",
    "verbose = config['verbose']\n",
    "inversion_save_fits_list = config['inversion_save_fits_list']\n",
    "inversion_save_errors_fits = config['inversion_save_errors_fits']\n",
    "inversion_save_lp_list = config['inversion_save_lp_list']\n",
    "inversion_save_errors_lp = config['inversion_save_errors_lp']\n",
    "delete_temp_files = config['delete_temp_files']\n",
    "# union of inversion_save_fits_list and inversion_save_lp_list\n",
    "inversion_save_list = list(set(inversion_save_fits_list + inversion_save_lp_list))\n",
    "wfa_blos_map = config['wfa_blos_map']\n",
    "\n",
    "# Extract the fits information from the header for the best frame\n",
    "tt = best_frame_index\n",
    "fits_info = config['fits_info']\n",
    "nx = fits_info['nx']\n",
    "ny = fits_info['ny']\n",
    "nw = fits_info['nw']\n",
    "nt = fits_info['nt']\n",
    "mu = fits_info['mu']\n",
    "x1 = fits_info['hplnt'][tt][0]\n",
    "x2 = fits_info['hplnt'][tt][1]\n",
    "y1 = fits_info['hpltt'][tt][0]\n",
    "y2 = fits_info['hpltt'][tt][1]\n",
    "tobs = fits_info['all_start_times'][tt]\n",
    "tstart = fits_info['start_time_obs']\n",
    "tend = fits_info['end_time_obs']\n",
    "hplnt = fits_info['hplnt']\n",
    "hpltt = fits_info['hpltt']\n",
    "all_start_times = fits_info['all_start_times']\n",
    "central_wavelength = fits_info['central_wavelength']\n",
    "\n",
    "# Reset the x and y ranges if cropping is enabled\n",
    "if crop:\n",
    "    x_list = np.linspace(x1, x2, num=nx)\n",
    "    y_list = np.linspace(y1, y2, num=ny)\n",
    "    x_list = x_list[xrange[0]:xrange[1]]\n",
    "    y_list = y_list[yrange[0]:yrange[1]]\n",
    "    x1 = x_list[0]\n",
    "    x2 = x_list[-1]\n",
    "    y1 = y_list[0]\n",
    "    y2 = y_list[-1]\n",
    "    nx = xsize\n",
    "    ny = ysize\n",
    "else:\n",
    "    print('No cropping is done\\n')\n",
    "\n",
    "# Load the fits header as a dictionary\n",
    "fits_header = iu.load_fits_header(crisp_im, out_dict=False)\n",
    "fits_header_dict = iu.load_fits_header(crisp_im, out_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename =crisp_im\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "hdr = fits.getheader(filename)\n",
    "nx = hdr['NAXIS1']\n",
    "ny = hdr['NAXIS2']\n",
    "nw = hdr['NAXIS3']\n",
    "ns = hdr['NAXIS4']\n",
    "nt = hdr['NAXIS5']\n",
    "start_time_obs = hdr['DATE-BEG']  # '2020-08-07T08:22:14'\n",
    "end_time_obs = hdr['DATE-END']\n",
    "avg_time_obs = hdr['DATE-AVG']\n",
    "# Read WCS data\n",
    "wcs_data = fits.getdata(filename, extname='WCS-TAB')\n",
    "# Extract the relevant data\n",
    "coords = np.array(wcs_data['HPLN+HPLT+WAVE+TIME'])[0]\n",
    "# Extract the coordinates\n",
    "hpln = coords[..., 0]  # (nt, nw, 2, 2) # four corners of the FOV?\n",
    "hplt = coords[..., 1]\n",
    "wave = coords[..., 2]\n",
    "time = coords[..., 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave2 = np.mean(wave, axis=(1, 2)) * 10  # Convert to Angstroms (nt, nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_sst_pointings_flag:\n",
    "    hp.plot_sst_pointings(tstart, hmi_con_series, hplnt, hpltt,figsize=(6, 6), email=email, save_dir=save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_hmi_ic_mag_flag:\n",
    "    hp.plot_hmi_ic_mag(tobs, hmi_con_series, hmi_mag_series, email, x1, x2, y1, y2, save_dir=save_dir, figsize=(10, 5),\n",
    "    is_north_up=is_north_up, fov_angle=fov_angle, shape=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_crisp_image_flag:\n",
    "    print('SST CRISP image with North up:', not(is_north_up))\n",
    "    iu.plot_crisp_image(crisp_im, tt=best_frame_index, ss=0, ww=0, figsize=(12,12), fontsize=10, rot_fov=fov_angle,\n",
    "    rot_to_north_up=not(is_north_up), crop=crop, xrange=xrange, yrange=yrange,\n",
    "    xtick_range=[x1,x2], ytick_range=[y1,y2], vmin=0.2, flip_lr=flip_lr)\n",
    "\n",
    "    iu.plot_crisp_image(crisp_im, tt=best_frame_index, ss=3, ww=nw // 4, figsize=(8,8), fontsize=10, rot_fov=fov_angle,\n",
    "    rot_to_north_up=not(is_north_up), crop=crop, xrange=xrange, yrange=yrange,\n",
    "    xtick_range=[x1,x2], ytick_range=[y1,y2], vmin=-0.2, flip_lr=flip_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the variables from the inversion configuration\n",
    "inversion_config = iu.load_yaml_config('inversion_config.yaml')\n",
    "\n",
    "dtype = inversion_config['dtype']\n",
    "sigma_strength= inversion_config['sigma_strength']\n",
    "sigma_list = inversion_config['sigma_list']\n",
    "erh = inversion_config['erh']\n",
    "init_model_params = inversion_config['init_model_params']\n",
    "nRandom1 = inversion_config['nRandom1']\n",
    "nIter1 = inversion_config['nIter1']\n",
    "chi2_thres1 = inversion_config['chi2_thres1']\n",
    "median_filter_chi2_mean_thres = inversion_config['median_filter_chi2_mean_thres']\n",
    "median_filter_size = inversion_config['median_filter_size']\n",
    "nRandom2 = inversion_config['nRandom2']\n",
    "nIter2 = inversion_config['nIter2']\n",
    "chi2_thres2 = inversion_config['chi2_thres2']\n",
    "nIter3 = inversion_config['nIter3']\n",
    "chi2_thres3 = inversion_config['chi2_thres3']\n",
    "alpha_strength = inversion_config['alpha_strength']\n",
    "alpha_list = inversion_config['alpha_list']\n",
    "nan_mask_replacements = inversion_config['nan_mask_replacements']\n",
    "nthreads = iu.get_nthreads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run the inversion for the best time index to get the initial guess for the Milne Eddington inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of variables obtained after the final inversion\n",
    "inversion_out_list = [\"Bstr\", \"Binc\", \"Bazi\", \"Vlos\", \"Vdop\", \"etal\", \"damp\", \"S0\", \"S1\", \"Blos\", \"Bhor\", \"Nan_mask\"]\n",
    "inverstion_error_out_list = [\"Bstr_err\", \"Binc_err\", \"Bazi_err\", \"Vlos_err\", \"Vdop_err\", \"etal_err\", \"damp_err\", \"S0_err\", \"S1_err\", \"Blos_err\", \"Bhor_err\", \"Nan_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_iteration = True\n",
    "count = 1\n",
    "for tt in time_range:\n",
    "    nt = len(time_range)\n",
    "    print(f'\\n\\n=== Processing Frame: {count}/{nt}, Index: {tt}, Time: {all_start_times[tt]} UT ===')\n",
    "    count += 1\n",
    "\n",
    "    # Load the CRISP image for a given time step\n",
    "    ll = meu.load_crisp_frame(crisp_im, tt, crop=crop, xrange=xrange, yrange=yrange)    \n",
    "    \n",
    "    # Setup the inversion parameters for the ME inversion\n",
    "    obs, sig, l0, me = meu.init_me_config(ll, sigma_strength, sigma_list, erh=erh, dtype=dtype, nthreads=nthreads)\n",
    "\n",
    "    if first_iteration:\n",
    "        # Obtain the initial model parameters after the inversion\n",
    "        Imodel = meu.init_model(me, ny, nx, init_model_params=init_model_params, dtype=dtype)\n",
    "\n",
    "    # Run the randomised ME inversion for the first time\n",
    "    print('=== BLOCK 1: Randomised ME Inversions ===')\n",
    "    Imodel, syn, chi2 = meu.run_randomised_me_inversion(Imodel, me, obs, sig, nRandom=nRandom1, nIter=nIter1, chi2_thres=chi2_thres1, mu=mu, verbose=verbose)\n",
    "    masked_chi2_mean = iu.masked_mean(chi2, ll.mask)\n",
    "    if verbose:\n",
    "        print(f'Masked chi2 mean: {masked_chi2_mean:.2f}')\n",
    "        iu.plot_inversion_output(Imodel, ll.mask, scale=scale, save_fig=False)\n",
    "        iu.plot_mag(Imodel, ll.mask, scale=scale, save_fig=False, v1min=blos_min, v1max=blos_max)\n",
    "\n",
    "    # if not init_model_from_sequence:\n",
    "    if not first_iteration:\n",
    "        median_filter_size = [2, 6, 8]\n",
    "        first_iteration = False\n",
    "        \n",
    "    # Apply median filter based on the chi2 mean to obtain a smoother model\n",
    "    print('=== BLOCK 2: Median-filtered output ===')\n",
    "    Imodel = meu.apply_median_filter_based_on_chi2(Imodel, masked_chi2_mean, median_filter_chi2_mean_thres, median_filter_size)\n",
    "    if verbose:    \n",
    "        iu.plot_inversion_output(Imodel,ll.mask,scale=scale, save_fig=False)\n",
    "        iu.plot_mag(Imodel,ll.mask,scale=scale, save_fig=False, v1min=blos_min, v1max=blos_max)\n",
    "    # init_model_from_sequence = True # Set the flag to True after the first iteration to avoid reinitialising the model\n",
    "\n",
    "    # Run the ME inversion again based on the smoothed model input\n",
    "    print('=== BLOCK 3: Randomised ME Inversions ===')\n",
    "    Imodel, syn, chi2 = meu.run_randomised_me_inversion(Imodel, me, obs, sig, nRandom=nRandom2, nIter=nIter2, chi2_thres=chi2_thres2, mu=mu, verbose=verbose)\n",
    "    masked_chi2_mean = iu.masked_mean(chi2, ll.mask)\n",
    "    if verbose:\n",
    "        print(f'Masked chi2 mean: {masked_chi2_mean:.2f}')\n",
    "        iu.plot_inversion_output(Imodel, ll.mask, scale=scale, save_fig=False)\n",
    "        iu.plot_mag(Imodel, ll.mask, scale=scale, save_fig=False, v1min=blos_min, v1max=blos_max)\n",
    "\n",
    "    # Run the spatially regularised ME inversion\n",
    "    print('=== BLOCK 4: Spatially Regularised ME Inversions ===')\n",
    "    Imodel, syn, chi2 = meu.run_spatially_regularized_inversion(me, Imodel, obs, sig, nIter3, chi2_thres3, mu,\n",
    "                        alpha_strength, alpha_list, method=1, delay_bracket=3,\n",
    "                        dtype=dtype,verbose=True)\n",
    "    Imodel = np.squeeze(Imodel)\n",
    "    errors = me.estimate_uncertainties(Imodel, obs, sig, mu=mu)\n",
    "    \n",
    "    # Apply cavity error correction to the model\n",
    "    # print('=== Cavity Error Correction ===')\n",
    "    corrected_mo = meu.correct_velocities_for_cavity_error(Imodel, ll.cmap, l0, global_offset=0.0)\n",
    "    if verbose:\n",
    "        iu.plot_inversion_output(corrected_mo,ll.mask,scale=scale, save_fig=True, save_dir=save_dir, figname=f'inversion_output_{tt}.pdf')\n",
    "        iu.plot_mag(corrected_mo,ll.mask,scale=scale, save_fig=True, save_dir=save_dir, figname=f'mag_output_{tt}.pdf', v1min=blos_min, v1max=blos_max)\n",
    "    else:\n",
    "        iu.plot_inversion_output(corrected_mo,ll.mask,scale=scale, save_fig=True, save_dir=save_dir, figname=f'inversion_output_{tt}.pdf', show_fig=False)\n",
    "        iu.plot_mag(corrected_mo,ll.mask,scale=scale, save_fig=True, save_dir=save_dir, figname=f'mag_output_{tt}.pdf', show_fig=False, v1min=blos_min, v1max=blos_max)\n",
    "\n",
    "    # Apply a mask to the model and errors to remove the NaN values from the edges\n",
    "    print('=== BLOCK 6: Apply Mask to Model and Errors ===')\n",
    "    masked_model= meu.apply_mask_to_model(corrected_mo, ll.mask, nan_mask_replacements)\n",
    "    masked_errors = meu.apply_mask_to_model(errors, ll.mask, nan_mask_replacements)\n",
    "    if verbose:\n",
    "        print(f'Masked chi2 mean: {masked_chi2_mean:.2f}')\n",
    "        iu.plot_inversion_output(masked_model,mask=None,scale=scale, save_fig=False)\n",
    "        iu.plot_inversion_output(masked_errors,mask=None,scale=scale, save_fig=False, apply_median_filter=True, filter_index=[1,2], filter_size=3)\n",
    "        iu.plot_mag(masked_model,mask=None,scale=scale, save_fig=False, v1min=blos_min, v1max=blos_max)\n",
    "\n",
    "    print('=== Calculating Blos and Bhor ===')\n",
    "    # Rearrange the model and errors for saving\n",
    "    model_im = rearrange(masked_model, 'ny nx nparams -> nparams ny nx')\n",
    "    errors_im = rearrange(masked_errors, 'ny nx nparams -> nparams ny nx')\n",
    "\n",
    "    # Clip the errors to the maximum value of the model parameters\n",
    "    for i in range(len(errors_im)):\n",
    "        errors_im[i] = np.clip(errors_im[i], a_min=0, a_max=np.max(np.abs(model_im[i])))\n",
    "\n",
    "    # Create arrays with uncertainties\n",
    "    B_with_errors = unumpy.uarray(model_im[0], errors_im[0])\n",
    "    inc_with_errors = unumpy.uarray(model_im[1], errors_im[1])\n",
    "\n",
    "    # Calculate Blos and Bhor with propagated errors\n",
    "    Blos_with_errors = B_with_errors * unumpy.cos(inc_with_errors)\n",
    "    Bhor_with_errors = B_with_errors * unumpy.sin(inc_with_errors)\n",
    "\n",
    "    # Extract nominal values and standard deviations\n",
    "    Blos = unumpy.nominal_values(Blos_with_errors)\n",
    "    Blos_err = unumpy.std_devs(Blos_with_errors)\n",
    "\n",
    "    Bhor = unumpy.nominal_values(Bhor_with_errors)\n",
    "    Bhor_err = unumpy.std_devs(Bhor_with_errors)\n",
    "\n",
    "    # Clip the errors to avoid very large values\n",
    "    Bhor_err_clipped = np.clip(Bhor_err, a_min=0, a_max=np.max(Bhor))\n",
    "    Blos_err_clipped = np.clip(Blos_err, a_min=0, a_max=np.max(np.abs(Blos)))\n",
    "\n",
    "    # Extend model_im by adding Blos and Bhor and 10 and 11 indices and Mask as 12\n",
    "    model_im = np.concatenate((model_im, Blos[np.newaxis], Bhor[np.newaxis], ll.mask[np.newaxis]), axis=0)\n",
    "    errors_im = np.concatenate((errors_im, Blos_err_clipped[np.newaxis], Bhor_err_clipped[np.newaxis], ll.mask[np.newaxis]), axis=0)\n",
    "\n",
    "    print('=== Saving the Inversion Output ===')\n",
    "    # Rearrange the model and errors for saving in IDL like format\n",
    "    idl_model_im = rearrange(model_im, 'nparams ny nx -> nparams nx ny')\n",
    "    idl_errors_im = rearrange(errors_im, 'nparams ny nx -> nparams nx ny')\n",
    "\n",
    "    # Save the inversion output in the fits format\n",
    "    time_string = all_start_times[tt].replace(':', '').replace(' ', '_T')\n",
    "    cen_wav = str(int(central_wavelength))\n",
    "\n",
    "    # Save the inversion output in the fits format\n",
    "    for var in inversion_save_list:\n",
    "        var_index = inversion_out_list.index(var)\n",
    "        sav_var = inversion_out_list[var_index]\n",
    "        out_file_name = os.path.join(save_dir, f'temp_{sav_var}_{cen_wav}_t_{tt}_{time_string}.fits')\n",
    "        iu.save_fits(idl_model_im[var_index], fits_header, out_file_name, overwrite=True, verbose=verbose)\n",
    "        if inversion_save_errors_fits or inversion_save_errors_lp and sav_var!='Nan_mask':\n",
    "            out_file_name = os.path.join(save_dir, f'temp_{sav_var}_err_{cen_wav}_t_{tt}_{time_string}.fits')\n",
    "            iu.save_fits(idl_errors_im[var_index], fits_header, out_file_name, overwrite=True, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_index_range = f\"{time_range[0]}-{time_range[-1]}\"\n",
    "obs_start_time = all_start_times[time_range[0]].replace(':', '').replace(' ', '_T')\n",
    "obs_end_time = all_start_times[time_range[-1]].replace(':', '').replace(' ', '_T')\n",
    "for var in inversion_save_list:\n",
    "    var_index = inversion_out_list.index(var)\n",
    "    sav_var = inversion_out_list[var_index]\n",
    "    temp_file_list = []\n",
    "    # create a numpy array with nx, ny , nt dimensions\n",
    "    full_var_data = np.zeros((nt, nx, ny))\n",
    "\n",
    "    if inversion_save_errors_fits or inversion_save_errors_lp:\n",
    "        full_err_data = np.zeros((nt, nx, ny))\n",
    "\n",
    "    for ii in range(len(time_range)):\n",
    "        tt = time_range[ii]\n",
    "        time_string = all_start_times[tt].replace(':', '').replace(' ', '_T')\n",
    "        out_file_name = os.path.join(save_dir, f'temp_{sav_var}_{cen_wav}_t_{tt}_{time_string}.fits')\n",
    "        var_data = iu.load_fits_data(out_file_name)\n",
    "        temp_file_list.append(out_file_name)\n",
    "        var_header = iu.load_fits_header(out_file_name, out_dict=False)\n",
    "        full_var_data[ii] = var_data\n",
    "        \n",
    "        if inversion_save_errors_fits or inversion_save_errors_lp and sav_var!='Nan_mask':\n",
    "            err_out_file_name = os.path.join(save_dir, f'temp_{sav_var}_err_{cen_wav}_t_{tt}_{time_string}.fits')\n",
    "            err_data = iu.load_fits_data(err_out_file_name)\n",
    "            temp_file_list.append(err_out_file_name)\n",
    "            full_err_data[ii] = err_data\n",
    "\n",
    "    if var in inversion_save_fits_list:\n",
    "        # Save the full variable data\n",
    "        out_file_name = os.path.join(save_dir, f'{sav_var}_{cen_wav}_{obs_start_time}_{obs_end_time}_t_{time_index_range}.fits')\n",
    "        iu.save_fits(full_var_data, var_header, out_file_name, overwrite=True, verbose=verbose)\n",
    "        if inversion_save_errors_fits and sav_var!='Nan_mask':\n",
    "            err_out_file_name = os.path.join(save_dir, f'{sav_var}_err_{cen_wav}_{obs_start_time}_{obs_end_time}_t_{time_index_range}.fits')\n",
    "            iu.save_fits(full_err_data, var_header, err_out_file_name, overwrite=True, verbose=verbose)\n",
    "\n",
    "    if var in inversion_save_lp_list:\n",
    "        # Save the inversion output in the LP format\n",
    "        lp_out_file_name = os.path.join(save_dir, f'{sav_var}_{cen_wav}_{obs_start_time}_{obs_end_time}_t_{time_index_range}.fcube')\n",
    "        lp_data = np.float32(rearrange(full_var_data, 'nt nx ny -> nx ny nt'))\n",
    "        lp.writeto(lp_out_file_name, lp_data, extraheader='', dtype=None, verbose=True, append=False)\n",
    "        \n",
    "        if inversion_save_errors_lp and sav_var!='Nan_mask':\n",
    "            lp_err_out_file_name = os.path.join(save_dir, f'{sav_var}_err_{cen_wav}_{obs_start_time}_{obs_end_time}_t_{time_index_range}.fcube')\n",
    "            lp_err_data = np.float32(rearrange(full_err_data, 'nt nx ny -> nx ny nt'))\n",
    "            lp.writeto(lp_err_out_file_name, lp_err_data, extraheader='', dtype=None, verbose=True, append=False)\n",
    "    \n",
    "    if delete_temp_files:\n",
    "        # Delete the temporary file using os module\n",
    "        for temp_file in temp_file_list:\n",
    "            if verbose:\n",
    "                print(f'Deleting temporary file: {temp_file}')\n",
    "            os.remove(temp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('=== Save the Run Config ===')\n",
    "# combine input_config and inversion_config dictionaries\n",
    "full_config = {**input_config, **inversion_config}\n",
    "\n",
    "# Save the input and inversion configuration as a separate file\n",
    "iu.save_yaml_config(full_config, 'full_config.yaml', save_dir=save_dir)\n",
    "# Save the fits information as a separate file\n",
    "iu.save_yaml_config(fits_info, 'fits_info.yaml', save_dir=save_dir, append_timestamp=False)\n",
    "\n",
    "# Save the fits header as a separate file\n",
    "\n",
    "iu.save_fits_header_as_text(fits_header_dict, 'fits_header.txt', save_dir=save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datadir = '/mn/stornext/d18/lapalma/reduc/2020/2020-08-07/CRISP/cubes_nb/'\n",
    "# blos_cube = datadir + 'Blos.6173_2020-08-07T08:22:14.icube'\n",
    "# bhor_cube = datadir + 'Bhor.6173_2020-08-07T08:22:14.icube'\n",
    "\n",
    "# data_dir = '/mn/stornext/d18/lapalma/reduc/2021/2021-06-22/CRISP/cubes_nb/'\n",
    "# blos_old = data_dir + 'Blos.6173_2021-06-22T08:17:48.fcube'\n",
    "# bhor_old = data_dir + 'Bhor.6173_2021-06-22T08:17:48.fcube'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blos_new = 'temp/Blos_6173_2021-06-22_T090257_2021-06-22_T090257_t_145-145.fcube'\n",
    "# bhor_new = 'temp/Bhor_6173_2021-06-22_T090257_2021-06-22_T090257_t_145-145.fcube'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iu.plot_sst_blos_bhor(blos_new, bhor_new, tt=0,xrange=xrange, yrange=yrange, figsize=(20,10), fontsize=12,\n",
    "#                       vmin1=-50, vmax1=50, vmax2=200)\n",
    "# iu.plot_sst_blos_bhor(blos_old, bhor_old, tt=145,xrange=xrange, yrange=yrange, figsize=(20,10), fontsize=12,\n",
    "#                       crop=crop, vmin1=-50, vmax1=50, vmax2=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
